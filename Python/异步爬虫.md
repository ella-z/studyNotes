# 异步爬虫
### 异步爬虫的方式
   - 多线程，多进程：
      - 好处：可以为相关的阻塞的操作单独开启线程或者进程，阻塞操作就可以异步执行。
      - 缺点：无法无限制的开启多线程或者多进程。
   - 线程池、进程池：
      - 好处：可以降低系统对进程或者线程创建和销毁的频率，从而很好地降低系统的开销。
      - 缺点：池中的线程或进程的数量有限。
   - 单线程+异步协程(Best way)
   
### 单线程+异步协程
   - 在异步协程中如果出现了同步模块相关对的代码，那么就无法实现异步。
   - 用到的几个概念：
      - event_loop：事件循环，相当于一个无限循环，可以把一些函数注册到这个事件循环上，当满足某些条件的时候，
      函数就会被循环执行。
      - coroutine：协程对象，可以将协程对象注册到事件循环中，它会被事件循环调用。可以使用async关键字来定义
      一个方法，这个方法在调用时不会立即被执行，而是返回一个协程对象。
      - task：任务，它是对协程对象的进一步封装，包含了任务的各个状态。
      - future：代表将来执行或还没有执行的任务，实际上和task没有本质却比。
      - async：定义一个协程。
      - await：用来挂起阻塞方法的执行。
      
 ```
  🌰：
    import asyncio
    import time
    
    async def request(url):
      print('正在下载',url)
      await asyncio.sleep(2)
      print('下载完毕',url)
      
    start = time.time()
    urls = [
      "www.baidu.com",
      "www.sogou.com",
      "www.naver.com"
    ]
    
    # 任务列表：存放多个任务对象
    stasks = []
    for url in urls:
      c = request(url)
      task = asyncio.ennsure_future(c)
      stasks.append(task)
    
    loop = asyncio.get_event_loop()
    loop.run_until_complete(asyncio.wait(stasks))
    
    print(time.time()-start) //6s
 ```
### aiohttp
- 异步请求，使用aiohttp模块中的ClientSession
 
 
 
 
 
 
